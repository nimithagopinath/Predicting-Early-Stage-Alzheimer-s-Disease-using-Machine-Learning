{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HgWsXzcObeXpXtb5xxhsKsfN-IoRN-iC",
      "authorship_tag": "ABX9TyOT3jap5qLCRZ84plrizT7g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimithagopinath/Predicting-Early-Stage-Alzheimer-s-Disease-using-Machine-Learning/blob/main/SEE_Machine_learning_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L27xeplThDb3",
        "outputId": "09d8c9da-3566-4e53-812b-edce74373a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set()\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Project/Data/archive (1)/oasis_longitudinal.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "UeUpEpofhfa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[df['Visit']==1] # use first visit data only because of the analysis we're doing\n",
        "df = df.reset_index(drop=True) # reset index after filtering first visit data\n",
        "df['M/F'] = df['M/F'].replace(['F','M'], [0,1]) # M/F column\n",
        "df['Group'] = df['Group'].replace(['Converted'], ['Demented']) # Target variable\n",
        "df['Group'] = df['Group'].replace(['Demented', 'Nondemented'], [1,0]) # Target variable\n",
        "df = df.drop(['MRI ID', 'Visit', 'Hand'], axis=1) # Drop unnecessary columns"
      ],
      "metadata": {
        "id": "I2ScTVsZiGNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bar drawing function\n",
        "def bar_chart(feature):\n",
        "    Demented = df[df['Group']==1][feature].value_counts()\n",
        "    Nondemented = df[df['Group']==0][feature].value_counts()\n",
        "    df_bar = pd.DataFrame([Demented,Nondemented])\n",
        "    df_bar.index = ['Demented','Nondemented']\n",
        "    df_bar.plot(kind='bar',stacked=True, figsize=(8,5))\n",
        "# Gender  and  Group ( Femal=0, Male=1)\n",
        "bar_chart('M/F')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Number of patients')\n",
        "plt.legend()\n",
        "plt.title('Gender and Demented rate')"
      ],
      "metadata": {
        "id": "9cyCNCqGiH9G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "07083cde-a06c-486e-8619-ebba7567b3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-22eae7b6e793>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstacked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Gender  and  Group ( Femal=0, Male=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mbar_chart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'M/F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Group'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of patients'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-22eae7b6e793>\u001b[0m in \u001b[0;36mbar_chart\u001b[0;34m(feature)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# bar drawing function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbar_chart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mDemented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mNondemented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDemented\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNondemented\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MMSE : Mini Mental State Examination\n",
        "# Nondemented = 0, Demented =1\n",
        "# Nondemented has higher test result ranging from 25 to 30.\n",
        "#Min 17 ,MAX 30\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'MMSE',shade= True)\n",
        "facet.set(xlim=(0, df['MMSE'].max()))\n",
        "facet.add_legend()\n",
        "plt.xlim(15.30)"
      ],
      "metadata": {
        "id": "-9i-CiVziSsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bar_chart('ASF') = Atlas Scaling Factor\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'ASF',shade= True)\n",
        "facet.set(xlim=(0, df['ASF'].max()))\n",
        "facet.add_legend()\n",
        "plt.xlim(0.5, 2)\n",
        "\n",
        "#eTIV = Estimated Total Intracranial Volume\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'eTIV',shade= True)\n",
        "facet.set(xlim=(0, df['eTIV'].max()))\n",
        "facet.add_legend()\n",
        "plt.xlim(900, 2100)\n",
        "\n",
        "#'nWBV' = Normalized Whole Brain Volume\n",
        "# Nondemented = 0, Demented =1\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'nWBV',shade= True)\n",
        "facet.set(xlim=(0, df['nWBV'].max()))\n",
        "facet.add_legend()\n",
        "plt.xlim(0.6,0.9)"
      ],
      "metadata": {
        "id": "1lGEkON4iW1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AGE. Nondemented =0, Demented =0\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'Age',shade= True)\n",
        "facet.set(xlim=(0, df['Age'].max()))\n",
        "facet.add_legend()\n",
        "plt.xlim(50,100)"
      ],
      "metadata": {
        "id": "GOt1iEcniZC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#'EDUC' = Years of Education\n",
        "# Nondemented = 0, Demented =1\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'EDUC',shade= True)\n",
        "facet.set(xlim=(df['EDUC'].min(), df['EDUC'].max()))\n",
        "facet.add_legend()\n",
        "plt.ylim(0, 0.16)"
      ],
      "metadata": {
        "id": "_MdAS0ZAidAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values by each column\n",
        "pd.isnull(df).sum()\n",
        "# The column, SES has 8 missing values"
      ],
      "metadata": {
        "id": "76m9xmssiiYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropped the 8 rows with missing values in the column, SES\n",
        "df_dropna = df.dropna(axis=0, how='any')\n",
        "pd.isnull(df_dropna).sum()"
      ],
      "metadata": {
        "id": "XuXPJeXgijay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropna['Group'].value_counts()"
      ],
      "metadata": {
        "id": "caDYXVDQincu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw scatter plot between EDUC and SES\n",
        "x = df['EDUC']\n",
        "y = df['SES']\n",
        "\n",
        "ses_not_null_index = y[~y.isnull()].index\n",
        "x = x[ses_not_null_index]\n",
        "y = y[ses_not_null_index]\n",
        "\n",
        "# Draw trend line in red\n",
        "z = np.polyfit(x, y, 1)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(x, y, 'go', x, p(x), \"r--\")\n",
        "plt.xlabel('Education Level(EDUC)')\n",
        "plt.ylabel('Social Economic Status(SES)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x2SbZ3gmiqNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['EDUC'])['SES'].median()"
      ],
      "metadata": {
        "id": "J4nfXQc4irxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"SES\"].fillna(df.groupby(\"EDUC\")[\"SES\"].transform(\"median\"), inplace=True)\n",
        "# I confirm there're no more missing values and all the 150 data were used.\n",
        "pd.isnull(df['SES']).value_counts()"
      ],
      "metadata": {
        "id": "r4vYg4zJit-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# Dataset with imputation\n",
        "Y = df['Group'].values # Target for the model\n",
        "X = df[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use\n",
        "\n",
        "# splitting into three sets\n",
        "X_trainval, X_test, Y_trainval, Y_test = train_test_split(\n",
        "    X, Y, random_state=0)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = MinMaxScaler().fit(X_trainval)\n",
        "X_trainval_scaled = scaler.transform(X_trainval)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "0ToMhK04iwyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset after dropping missing value rows\n",
        "Y = df_dropna['Group'].values # Target for the model\n",
        "X = df_dropna[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use\n",
        "\n",
        "# splitting into three sets\n",
        "X_trainval_dna, X_test_dna, Y_trainval_dna, Y_test_dna = train_test_split(\n",
        "    X, Y, random_state=0)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = MinMaxScaler().fit(X_trainval_dna)\n",
        "X_trainval_scaled_dna = scaler.transform(X_trainval_dna)\n",
        "X_test_scaled_dna = scaler.transform(X_test_dna)"
      ],
      "metadata": {
        "id": "m3kqAoD2i0vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Logistic regression\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc\n",
        "acc = [] # list to store all performance metric"
      ],
      "metadata": {
        "id": "1eZMU3UVjB6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset with imputation\n",
        "best_score=0\n",
        "kfolds=5 # set the number of folds\n",
        "\n",
        "for c in [0.001, 0.1, 1, 10, 100]:\n",
        "    logRegModel = LogisticRegression(C=c)\n",
        "    # perform cross-validation\n",
        "    scores = cross_val_score(logRegModel, X_trainval, Y_trainval, cv=kfolds, scoring='accuracy') # Get recall for each parameter setting\n",
        "\n",
        "    # compute mean cross-validation accuracy\n",
        "    score = np.mean(scores)\n",
        "\n",
        "    # Find the best parameters and score\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_parameters = c\n",
        "\n",
        "        # rebuild a model on the combined training and validation set\n",
        "SelectedLogRegModel = LogisticRegression(C=best_parameters).fit(X_trainval_scaled, Y_trainval)\n",
        "\n",
        "test_score = SelectedLogRegModel.score(X_test_scaled, Y_test)\n",
        "PredictedOutput = SelectedLogRegModel.predict(X_test_scaled)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on validation set is:\", best_score)\n",
        "print(\"Best parameter for regularization (C) is: \", best_parameters)\n",
        "print(\"Test accuracy with best C parameter is\", test_score)\n",
        "print(\"Test recall with the best C parameter is\", test_recall)\n",
        "print(\"Test AUC with the best C parameter is\", test_auc)\n",
        "m = 'Logistic Regression (w/ imputation)'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])\n"
      ],
      "metadata": {
        "id": "xZ6QlqR_jF2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset after dropping missing value rows\n",
        "best_score=0\n",
        "kfolds=5 # set the number of folds\n",
        "\n",
        "for c in [0.001, 0.1, 1, 10, 100]:\n",
        "    logRegModel = LogisticRegression(C=c)\n",
        "    # perform cross-validation\n",
        "    scores = cross_val_score(logRegModel, X_trainval_scaled_dna, Y_trainval_dna, cv=kfolds, scoring='accuracy')\n",
        "\n",
        "    # compute mean cross-validation accuracy\n",
        "    score = np.mean(scores)\n",
        "\n",
        "    # Find the best parameters and score\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_parameters = c\n",
        "# rebuild a model on the combined training and validation set\n",
        "SelectedLogRegModel = LogisticRegression(C=best_parameters).fit(X_trainval_scaled_dna, Y_trainval_dna)\n",
        "\n",
        "test_score = SelectedLogRegModel.score(X_test_scaled_dna, Y_test_dna)\n",
        "PredictedOutput = SelectedLogRegModel.predict(X_test_scaled)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on validation set is:\", best_score)\n",
        "print(\"Best parameter for regularization (C) is: \", best_parameters)\n",
        "print(\"Test accuracy with best C parameter is\", test_score)\n",
        "print(\"Test recall with the best C parameter is\", test_recall)\n",
        "print(\"Test AUC with the best C parameter is\", test_auc)\n",
        "\n",
        "m = 'Logistic Regression (w/ dropna)'\n",
        "acc.append([m, test_score, test_recall, test_recall, fpr, tpr, thresholds])"
      ],
      "metadata": {
        "id": "cO9Bn2eWYTKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SVM\n",
        "\n",
        "#C: Penalty parameter C of the error term. [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "\n",
        "#gamma: kernel coefficient. [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "\n",
        "#kernel: kernel type. ['rbf', 'linear', 'poly', 'sigmoid']\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "for c_paramter in [0.001, 0.01, 0.1, 1, 10, 100, 1000]: #iterate over the values we need to try for the parameter C\n",
        "    for gamma_paramter in [0.001, 0.01, 0.1, 1, 10, 100, 1000]: #iterate over the values we need to try for the parameter gamma\n",
        "        for k_parameter in ['rbf', 'linear', 'poly', 'sigmoid']: # iterate over the values we need to try for the kernel parameter\n",
        "            svmModel = SVC(kernel=k_parameter, C=c_paramter, gamma=gamma_paramter) #define the model\n",
        "            # perform cross-validation\n",
        "            scores = cross_val_score(svmModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n",
        "            # the training set will be split internally into training and cross validation\n",
        "\n",
        "            # compute mean cross-validation accuracy\n",
        "            score = np.mean(scores)\n",
        "            # if we got a better score, store the score and parameters\n",
        "            if score > best_score:\n",
        "                best_score = score #store the score\n",
        "                best_parameter_c = c_paramter #store the parameter c\n",
        "                best_parameter_gamma = gamma_paramter #store the parameter gamma\n",
        "                best_parameter_k = k_parameter\n",
        "# rebuild a model with best parameters to get score\n",
        "SelectedSVMmodel = SVC(C=best_parameter_c, gamma=best_parameter_gamma, kernel=best_parameter_k).fit(X_trainval_scaled, Y_trainval)\n",
        "\n",
        "test_score = SelectedSVMmodel.score(X_test_scaled, Y_test)\n",
        "PredictedOutput = SelectedSVMmodel.predict(X_test_scaled)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on cross validation set is:\", best_score)\n",
        "print(\"Best parameter for c is: \", best_parameter_c)\n",
        "print(\"Best parameter for gamma is: \", best_parameter_gamma)\n",
        "print(\"Best parameter for kernel is: \", best_parameter_k)\n",
        "print(\"Test accuracy with the best parameters is\", test_score)\n",
        "print(\"Test recall with the best parameters is\", test_recall)\n",
        "print(\"Test AUC with the best parameter is\", test_auc)\n",
        "\n",
        "m = 'SVM'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"
      ],
      "metadata": {
        "id": "bh7eSANeagiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Decision Tree\n",
        "#Maximum depth. [1, 2, ..., 8]\n",
        "\n",
        "#8 is the number of features\n",
        "\n",
        "\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "for md in range(1, 9): # iterate different maximum depth values\n",
        "    # train the model\n",
        "    treeModel = DecisionTreeClassifier(random_state=0, max_depth=md, criterion='gini')\n",
        "    # perform cross-validation\n",
        "    scores = cross_val_score(treeModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n",
        "\n",
        "    # compute mean cross-validation accuracy\n",
        "    score = np.mean(scores)\n",
        "\n",
        "    # if we got a better score, store the score and parameters\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_parameter = md\n",
        "\n",
        "# Rebuild a model on the combined training and validation set\n",
        "SelectedDTModel = DecisionTreeClassifier(max_depth=best_parameter).fit(X_trainval_scaled, Y_trainval )\n",
        "test_score = SelectedDTModel.score(X_test_scaled, Y_test)\n",
        "PredictedOutput = SelectedDTModel.predict(X_test_scaled)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on validation set is:\", best_score)\n",
        "print(\"Best parameter for the maximum depth is: \", best_parameter)\n",
        "print(\"Test accuracy with best parameter is \", test_score)\n",
        "print(\"Test recall with best parameters is \", test_recall)\n",
        "print(\"Test AUC with the best parameter is \", test_auc)\n",
        "\n",
        "m = 'Decision Tree'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])\n",
        "print(\"Feature importance: \")\n",
        "np.array([X.columns.values.tolist(), list(SelectedDTModel.feature_importances_)]).T\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "dot_data=export_graphviz(SelectedDTModel, feature_names=X_trainval.columns.values.tolist(),out_file=None)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph\n",
        "\n"
      ],
      "metadata": {
        "id": "IGkb32jLa2Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##6.E Random Forest Classifier\n",
        "#n_estimators(M): the number of trees in the forest\n",
        "\n",
        "#max_features(d): the number of features to consider when looking for the best split\n",
        "\n",
        "#max_depth(m): the maximum depth of the tree.\n",
        "\n",
        "\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "for M in range(2, 15, 2): # combines M trees\n",
        "    for d in range(1, 9): # maximum number of features considered at each split\n",
        "        for m in range(1, 9): # maximum depth of the tree\n",
        "            # train the model\n",
        "            # n_jobs(4) is the number of parallel computing\n",
        "            forestModel = RandomForestClassifier(n_estimators=M, max_features=d, n_jobs=4,\n",
        "                                          max_depth=m, random_state=0)\n",
        "\n",
        "            # perform cross-validation\n",
        "            scores = cross_val_score(forestModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n",
        "\n",
        "            # compute mean cross-validation accuracy\n",
        "            score = np.mean(scores)\n",
        "\n",
        "            # if we got a better score, store the score and parameters\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_M = M\n",
        "                best_d = d\n",
        "                best_m = m\n",
        "\n",
        "# Rebuild a model on the combined training and validation set\n",
        "SelectedRFModel = RandomForestClassifier(n_estimators=M, max_features=d,\n",
        "                                          max_depth=m, random_state=0).fit(X_trainval_scaled, Y_trainval )\n",
        "\n",
        "PredictedOutput = SelectedRFModel.predict(X_test_scaled)\n",
        "test_score = SelectedRFModel.score(X_test_scaled, Y_test)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on validation set is:\", best_score)\n",
        "print(\"Best parameters of M, d, m are: \", best_M, best_d, best_m)\n",
        "print(\"Test accuracy with the best parameters is\", test_score)\n",
        "print(\"Test recall with the best parameters is:\", test_recall)\n",
        "print(\"Test AUC with the best parameters is:\", test_auc)\n",
        "\n",
        "m = 'Random Forest'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])\n",
        "\n",
        "\n",
        "print(\"Feature importance: \")\n",
        "np.array([X.columns.values.tolist(), list(SelectedRFModel.feature_importances_)]).T\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1o0HlyHlbKiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 6.F AdaBoost\n",
        "\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "for M in range(2, 15, 2): # combines M trees\n",
        "    for lr in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
        "        # train the model\n",
        "        boostModel = AdaBoostClassifier(n_estimators=M, learning_rate=lr, random_state=0)\n",
        "\n",
        "        # perform cross-validation\n",
        "        scores = cross_val_score(boostModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n",
        "\n",
        "        # compute mean cross-validation accuracy\n",
        "        score = np.mean(scores)\n",
        "\n",
        "        # if we got a better score, store the score and parameters\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_M = M\n",
        "            best_lr = lr\n",
        "\n",
        "# Rebuild a model on the combined training and validation set\n",
        "SelectedBoostModel = AdaBoostClassifier(n_estimators=M, learning_rate=lr, random_state=0).fit(X_trainval_scaled, Y_trainval )\n",
        "\n",
        "PredictedOutput = SelectedBoostModel.predict(X_test_scaled)\n",
        "test_score = SelectedRFModel.score(X_test_scaled, Y_test)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on validation set is:\", best_score)\n",
        "print(\"Best parameter of M is: \", best_M)\n",
        "print(\"best parameter of LR is: \", best_lr)\n",
        "print(\"Test accuracy with the best parameter is\", test_score)\n",
        "print(\"Test recall with the best parameters is:\", test_recall)\n",
        "print(\"Test AUC with the best parameters is:\", test_auc)\n",
        "\n",
        "m = 'AdaBoost'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])\n",
        "\n",
        "print(\"Feature importance: \")\n",
        "np.array([X.columns.values.tolist(), list(SelectedBoostModel.feature_importances_)]).T"
      ],
      "metadata": {
        "id": "yvNCQy8CbYmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance Metric for each model\n",
        "result = pd.DataFrame(acc, columns=['Model', 'Accuracy', 'Recall', 'AUC', 'FPR', 'TPR', 'TH'])\n",
        "result[['Model', 'Accuracy', 'Recall', 'AUC']]\n",
        "\n"
      ],
      "metadata": {
        "id": "IOZrpGE6b1St"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}